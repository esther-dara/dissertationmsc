# dissertationmsc
**Fairness in NHS Readmissions Prediction with FAIM**

This repository contains the code and outputs for my MSc dissertation project, which replicated and extended the Fairness-Aware Interpretable Modelling (FAIM) framework (Liu et al., 2023) using NHS readmissions data (2011â€“2024).

The project investigates whether AI models can balance predictive accuracy with fairness across sensitive groups (Gender, Age), contributing to SDG 3 (Good Health & Well-being) and SDG 10 (Reduced Inequalities).

ğŸ“‚ Repository Structure

data/  
notebooks/ â†’ Jupyter/Colab notebooks with executed code and outputs

src/ â†’ Clean, modular Python scripts (preprocessing, training, fairness evaluation, plots)

results/ â†’ Tables, fairness metrics, and visualisations

original_code/ â†’ Link/reference to FAIMâ€™s original repository

requirements.txt â†’ Python dependencies

LICENSE â†’ MIT open-source licence


âš™ï¸ How to Run

Clone this repo

Install requirements:

pip install -r requirements.txt

Follow pipeline:

preprocessing.py â†’ clean & encode NHS data

train_faim.py â†’ generate nearly-optimal models

fairness_eval.py â†’ evaluate with fairlearn (Equalised Odds, Equal Opportunity, Predictive Parity, etc.)

test_eval.py â†’ final test set evaluation


ğŸ“Š Key Contributions

Replicated FAIM on NHS data (first application beyond US datasets)

Extended fairness evaluation with Predictive Parity using fairlearn

Identified that Equalised Odds implied parity, but disparities surfaced in other metrics

Demonstrated practical reproducibility challenges and methodological adaptations


ğŸ“– Citation

If you use this code, please cite:

Liu, Y. et al. (2023). Fairness-Aware Interpretable Modeling for Healthcare AI
