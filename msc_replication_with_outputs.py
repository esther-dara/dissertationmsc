# -*- coding: utf-8 -*-
"""MSC Replication with Outputs

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GJmmb8gPSc8Q5DcXmEP94eUBxTCi7O3r
"""

!pip install seaborn==0.12.2 shap patchworklib
!rm -rf /content/FAIM /content/ShapleyVIC
!git clone https://github.com/nliulab/FAIM.git /content/FAIM
!git clone https://github.com/nliulab/ShapleyVIC.git /content/ShapleyVIC

!pip install tqdm_joblib

!pip install sage-importance

# Add repos to Python path
import sys
sys.path.append("/content/FAIM")
sys.path.append("/content/ShapleyVIC/python")  # ShapleyVIC stores code here

pip install aif360

pip install fairlearn

# Test imports
from FAIM import FAIMGenerator, FairBase
print("‚úÖ FAIM + ShapleyVIC ready")

import pandas as pd, numpy as np
from sklearn.model_selection import train_test_split

np.random.seed(42)
dat_all = pd.DataFrame({
    "Age": np.random.randint(20, 80, 500),
    "gender": np.random.choice([0,1], 500),
    "race": np.random.choice([0,1,2,3,4], 500),
    "triage_acuity": np.random.choice([1,2,3,4,5], 500),
    "triage_o2sat": np.random.randint(90, 100, 500),
    "triage_temperature": np.random.randint(36, 39, 500),
    "n_hosp_365d": np.random.randint(0, 3, 500),
    "triage_pain": np.random.randint(0, 10, 500),
    "triage_heartrate": np.random.randint(60, 120, 500),
    "triage_resprate": np.random.randint(12, 25, 500),
    "triage_dbp": np.random.randint(60, 90, 500),
    "triage_sbp": np.random.randint(100, 160, 500),
    "label": np.random.choice([0,1], 500)
})

# Train / Expl / Test split
dat_train, temp = train_test_split(dat_all, test_size=0.4, random_state=42)
dat_expl, dat_test = train_test_split(temp, test_size=0.5, random_state=1)

print("Train:", len(dat_train), "Expl:", len(dat_expl), "Test:", len(dat_test))

esi_dic = {1:"High risk", 2:"High risk", 3:"@Low risk", 4:"@Low risk", 5:"@Low risk"}
race_dic = {0:"Asian", 1:"Black", 2:"Hispanic", 3:"Others", 4:"@White"}
gender_dic = {0:"Female", 1:"@Male"}

for d in [dat_train, dat_expl, dat_test]:
    d["triage_acuity"] = d["triage_acuity"].map(esi_dic)
    d["race"] = d["race"].map(race_dic)
    d["gender"] = d["gender"].map(gender_dic)

var_dict = {
    "Age":"Age", "gender":"Gender", "race":"Race", "triage_acuity":"ESI",
    "triage_o2sat":"SPO2", "triage_temperature":"Temperature",
    "n_hosp_365d":"Hospitalizations last year", "triage_pain":"Pain scale",
    "triage_heartrate":"Heartrate", "triage_resprate":"Respirate rate",
    "triage_dbp":"Diastolic blood pressure", "triage_sbp":"Systolic blood pressure"
}

for d in [dat_train, dat_expl, dat_test]:
    d.rename(columns=var_dict, inplace=True)

y_name = "label"
colnames = ['Age','ESI','Systolic blood pressure','Heartrate',
            'Diastolic blood pressure','Temperature','Pain scale',
            'SPO2','Respirate rate','Hospitalizations last year','Gender','Race']
x_names_cat = ["ESI","Gender","Race"]
sen = ["Gender","Race"]
sen_ref = {"Gender":"@Male","Race":"@White"}

output_dir = "output"

from FAIM import fairness_modelling
from ShapleyVIC import model

def patched_optimal_model(self, selected_vars, selected_vars_cat):
    x = self.dat_train.drop(
        columns=[c for c in self.dat_train.columns if c == self.y_name or c not in selected_vars]
    )

    # Call ShapleyVIC without sample_w
    model_object = model.models(
        x=x,
        y=self.dat_train[self.y_name],
        x_names_cat=selected_vars_cat,
        output_dir=self.output_dir,
        criterion=self.criterion
    )
    return model_object

# Apply patch
fairness_modelling.FAIMGenerator.optimal_model = patched_optimal_model
print("‚úÖ Patched FAIMGenerator.optimal_model to remove sample_w")

faim_obj = FAIMGenerator(
    dat_train,
    selected_vars=colnames,
    selected_vars_cat=x_names_cat,
    y_name=y_name,
    sen_name=sen,
    sen_var_ref=sen_ref,
    criterion="auc",
    m=200, n_final=50,  # use smaller than README for speed
    output_dir=output_dir,
    without_sen="auto",
    pre=False
)

faim_obj.FAIM_model(dat_expl)
print("‚úÖ Nearly-optimal models generated")

from FAIM import fairness_modelling

def safe_transmit(self, targeted_metrics=["Equalized Odds","Equal Opportunity"], threshold=1.0, **kwargs):
    print(f"‚ö†Ô∏è Using safe_transmit with threshold={threshold}")
    ids = (self.fairmetrics_df[targeted_metrics] < threshold).all(axis=1)
    fairmetrics_df = self.fairmetrics_df.loc[ids, targeted_metrics]

    if fairmetrics_df.empty:
        print("‚ö†Ô∏è No models passed fairness threshold. Returning best overall model instead.")
        best_id = self.fairmetrics_df.index[0]
    else:
        best_id = fairmetrics_df.index[0]

    best_sen_exclusion = self.fairmetrics_df["sen_var_exclusion"].iloc[best_id]

    # ‚úÖ Save to object so .test() works
    self.best_sen_exclusion = best_sen_exclusion

    best_results = {
        "best_coef": None,
        "best_sen_exclusion": best_sen_exclusion,
        "best_optim_base_obj": None
    }
    return best_results, fairmetrics_df

# Reapply patch
fairness_modelling.FAIMGenerator.transmit = safe_transmit
print("‚úÖ Patched transmit: now sets faim_obj.best_sen_exclusion")

#Step 2: Fairness Transmission
best_results, fair_idx_df = faim_obj.transmit(
    targeted_metrics=["Equalized Odds","Equal Opportunity","BER Equality"],
    threshold=1.0
)

print("\n‚úÖ Step 2 complete")
print("Best model sensitive variable exclusion:", best_results['best_sen_exclusion'])
print("\nFairness transmission results:\n", fair_idx_df.head())

#Step Three: Fairness Metrics by Age and Gender
from fairlearn.metrics import equalized_odds_difference, demographic_parity_difference
from sklearn.metrics import accuracy_score

# True labels
y_true = dat_test[y_name].values

# To be replaced with actual FAIM predictions after test
y_pred_bin = np.random.randint(0, 2, len(dat_test))

# --- Fairness evaluation by Gender ---
eq_odds_gender = equalized_odds_difference(y_true, y_pred_bin, sensitive_features=dat_test["Gender"])
dp_gender = demographic_parity_difference(y_true, y_pred_bin, sensitive_features=dat_test["Gender"])
acc_gender = accuracy_score(y_true, y_pred_bin)

print("Fairness metrics by Gender:")
print("  Accuracy:", acc_gender)
print("  Equalized Odds Difference:", eq_odds_gender)
print("  Demographic Parity Difference:", dp_gender)

# --- Fairness evaluation by Race ---
eq_odds_race = equalized_odds_difference(y_true, y_pred_bin, sensitive_features=dat_test["Race"])
dp_race = demographic_parity_difference(y_true, y_pred_bin, sensitive_features=dat_test["Race"])
acc_race = accuracy_score(y_true, y_pred_bin)

print("\nFairness metrics by Race:")
print("  Accuracy:", acc_race)
print("  Equalized Odds Difference:", eq_odds_race)
print("  Demographic Parity Difference:", dp_race)

# Cast metrics to float before plotting
import matplotlib.pyplot as plt

# Ensuring values are plain Python floats
eq_odds_gender_val = float(eq_odds_gender)
dp_gender_val = float(dp_gender)
eq_odds_race_val = float(eq_odds_race)
dp_race_val = float(dp_race)

# Data for bar chart
metrics = ["Equalized Odds", "Demographic Parity"]
gender_vals = [eq_odds_gender_val, dp_gender_val]
race_vals = [eq_odds_race_val, dp_race_val]

x = range(len(metrics))

plt.figure(figsize=(6,5))
plt.bar([i-0.2 for i in x], gender_vals, width=0.4, label="Gender")
plt.bar([i+0.2 for i in x], race_vals, width=0.4, label="Race")

plt.xticks(x, metrics)
plt.ylabel("Fairness Gap (difference)")
plt.title("Fairness Gaps by Sensitive Attribute")
plt.legend()
plt.show()

"""Loading and Cleaning NHS Admissions Data"""



from google.colab import files

uploaded = files.upload()

import pandas as pd
file_path = list(uploaded.keys())[0]
df = pd.read_csv(file_path)

print("File loaded successfully!")
print(df.head())

print(dat_all.columns.tolist())

#Checking full coverage of dataset
print(df["Year"].unique())
print("Total years:", df["Year"].nunique())

# --- Keep only relevant columns ---
cols_to_keep = ["Year", "Age Breakdown", "Sex Breakdown",
                "Numerator", "Denominator", "Indicator value"]
df = df[cols_to_keep]

# --- Drop aggregate categories ---
df = df[(df["Age Breakdown"] != "All") & (df["Sex Breakdown"] != "Persons")]

# --- Convert numeric columns ---
for col in ["Numerator", "Denominator", "Indicator value"]:
    df[col] = pd.to_numeric(df[col], errors="coerce")

# Drop rows with missing values in critical fields
df = df.dropna(subset=["Numerator", "Denominator", "Indicator value"])

# --- Create target variable (ReadmissionRate) ---
df["ReadmissionRate"] = df["Numerator"] / df["Denominator"]

# Reset index
df_cleaned = df.reset_index(drop=True)

print("‚úÖ Dataset cleaned and prepared")
print("Shape:", df_cleaned.shape)
print(df_cleaned.head(10))

# --- Extra: Dataset summary ---
print("\nüìÖ Years covered:", df_cleaned["Year"].unique())
print("Total years:", df_cleaned["Year"].nunique())
print("\nCounts per year:\n", df_cleaned["Year"].value_counts().sort_index())

import numpy as np

# Use the median readmission rate as threshold
threshold = df_cleaned["ReadmissionRate"].median()
df_cleaned["label"] = (df_cleaned["ReadmissionRate"] > threshold).astype(int)

print("Threshold used:", threshold)
print(df_cleaned[["ReadmissionRate", "label"]].head(10))

# Map Gender
df_cleaned["Gender"] = df_cleaned["Sex Breakdown"].replace({
    "Male": "@Male",   # mark reference group with '@'
    "Female": "Female"
})

# Age groups
df_cleaned["AgeGroup"] = df_cleaned["Age Breakdown"]

y_name = "label"
colnames = ["Year", "AgeGroup", "Numerator", "Denominator", "Gender"]
x_names_cat = ["Gender", "AgeGroup"]
sen = ["Gender", "AgeGroup"]
sen_ref = {"Gender": "@Male", "AgeGroup": "<16"}   # choose <16 as reference for now

from sklearn.model_selection import train_test_split

dat_train, temp = train_test_split(df_cleaned, test_size=0.4, random_state=42)
dat_expl, dat_test = train_test_split(temp, test_size=0.5, random_state=1)

print("Train:", len(dat_train), "Expl:", len(dat_expl), "Test:", len(dat_test))

"""Buiding FAIM pipeline for NHS Dataset"""

# Encode categorical columns as category dtype
for col in ["Year", "AgeGroup", "Gender"]:
    df_cleaned[col] = df_cleaned[col].astype("category")

print(df_cleaned[["Year", "AgeGroup", "Gender"]].dtypes)

from FAIM import FAIMGenerator
from sklearn.model_selection import train_test_split
import os

# --- Encode categorical columns as numeric codes ---
for col in ["Year", "AgeGroup", "Gender"]:
    df_cleaned[col] = df_cleaned[col].astype("category").cat.codes

print("‚úÖ Encoded categorical columns as numeric codes")
print(df_cleaned[["Year", "AgeGroup", "Gender"]].head())

# --- Create binary outcome variable using median split ---
threshold = df_cleaned["ReadmissionRate"].median()
df_cleaned["ReadmissionBinary"] = (df_cleaned["ReadmissionRate"] > threshold).astype(int)

print("Outcome balance after median split:")
print(df_cleaned["ReadmissionBinary"].value_counts())

# --- Define FAIM variables ---
y_name = "ReadmissionBinary"   # ‚úÖ binary classification target
colnames = ["Year", "AgeGroup", "Numerator", "Denominator", "Gender"]
x_names_cat = ["Gender", "AgeGroup"]
sen = ["Gender", "AgeGroup"]
sen_ref = {"Gender": 0, "AgeGroup": 0}   # ‚úÖ reference groups exist in data

# --- Train/Expl/Test split ---
dat_train, temp = train_test_split(df_cleaned, test_size=0.4, random_state=42)
dat_expl, dat_test = train_test_split(temp, test_size=0.5, random_state=1)

print("Train:", len(dat_train), "Expl:", len(dat_expl), "Test:", len(dat_test))

# --- Initialise FAIM ---
output_dir = "output"
if not os.path.exists(output_dir):
    os.makedirs(output_dir)

faim_obj = FAIMGenerator(
    dat_train,
    selected_vars=colnames,
    selected_vars_cat=x_names_cat,
    y_name=y_name,
    sen_name=sen,
    sen_var_ref=sen_ref,
    output_dir=output_dir,
    criterion="auc",
    m=50,        # fast config
    n_final=10,
    without_sen="no",   # ‚úÖ force fairness metrics to be computed
    pre=False
)

# --- Generate nearly-optimal models ---
faim_obj.FAIM_model(dat_expl)
print("‚úÖ Step 1 complete ‚Äî Nearly-optimal models generated")

# --- Check fairness metrics availability ---
print("Fairness metrics available:", faim_obj.fairmetrics_df.columns.tolist())
print(faim_obj.fairmetrics_df.head())

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
from fairlearn.metrics import MetricFrame, selection_rate, true_positive_rate, false_positive_rate

# --- Prepare data (X = features, y = binary outcome) ---
X_train = dat_train[colnames]
y_train = dat_train[y_name]
X_expl = dat_expl[colnames]
y_expl = dat_expl[y_name]

# --- Train a simple classifier (logistic regression as baseline) ---
clf = LogisticRegression(max_iter=1000)
clf.fit(X_train, y_train)

# --- Predictions on expl set ---
y_pred = clf.predict(X_expl)

# --- Define fairness metrics ---
metrics = {
    "accuracy": accuracy_score,
    "selection_rate": selection_rate,
    "TPR (Equal Opportunity)": true_positive_rate,
    "FPR (Equalized Odds)": false_positive_rate,
}

# --- Fairness by Gender ---
mf_gender = MetricFrame(
    metrics=metrics,
    y_true=y_expl,
    y_pred=y_pred,
    sensitive_features=dat_expl["Gender"]
)
print("‚úÖ Step 2 complete ‚Äî Fairness metrics by Gender")
print(mf_gender.by_group)
print("\nOverall metrics:\n", mf_gender.overall)

# --- Fairness by AgeGroup ---
mf_age = MetricFrame(
    metrics=metrics,
    y_true=y_expl,
    y_pred=y_pred,
    sensitive_features=dat_expl["AgeGroup"]
)
print("\n‚úÖ Step 2 complete ‚Äî Fairness metrics by AgeGroup")
print(mf_age.by_group)
print("\nOverall metrics:\n", mf_age.overall)

# --- Predictions on test set ---
X_test = dat_test[colnames]
y_test = dat_test[y_name]
y_pred_test = clf.predict(X_test)

# --- Overall performance on test set ---
test_acc = accuracy_score(y_test, y_pred_test)
print("‚úÖ Step 3 complete ‚Äî Test set evaluation")
print(f"Test Accuracy: {test_acc:.3f}")

# --- Fairness by Gender on test set ---
mf_gender_test = MetricFrame(
    metrics=metrics,
    y_true=y_test,
    y_pred=y_pred_test,
    sensitive_features=dat_test["Gender"]
)
print("\nFairness metrics by Gender (Test):")
print(mf_gender_test.by_group)

# --- Fairness by AgeGroup on test set ---
mf_age_test = MetricFrame(
    metrics=metrics,
    y_true=y_test,
    y_pred=y_pred_test,
    sensitive_features=dat_test["AgeGroup"]
)
print("\nFairness metrics by AgeGroup (Test):")
print(mf_age_test.by_group)

"""Predictive Parity"""

from sklearn.metrics import precision_score

# --- Extend fairness metrics with Predictive Parity (Precision) ---
metrics = {
    "accuracy": accuracy_score,
    "selection_rate": selection_rate,
    "TPR (Equal Opportunity)": true_positive_rate,
    "FPR (Equalized Odds)": false_positive_rate,
    "Predictive Parity (Precision)": precision_score
}

# --- Fairness by Gender (Expl) ---
mf_gender = MetricFrame(
    metrics=metrics,
    y_true=y_expl,
    y_pred=y_pred,
    sensitive_features=dat_expl["Gender"]
)
print("‚úÖ Step 2 complete ‚Äî Fairness metrics by Gender (Expl)")
print(mf_gender.by_group)
print("\nOverall metrics:\n", mf_gender.overall)

# --- Fairness by AgeGroup (Expl) ---
mf_age = MetricFrame(
    metrics=metrics,
    y_true=y_expl,
    y_pred=y_pred,
    sensitive_features=dat_expl["AgeGroup"]
)
print("\n‚úÖ Step 2 complete ‚Äî Fairness metrics by AgeGroup (Expl)")
print(mf_age.by_group)
print("\nOverall metrics:\n", mf_age.overall)

# --- Fairness by Gender (Test) ---
mf_gender_test = MetricFrame(
    metrics=metrics,
    y_true=y_test,
    y_pred=y_pred_test,
    sensitive_features=dat_test["Gender"]
)
print("\nFairness metrics by Gender (Test):")
print(mf_gender_test.by_group)
print("\nOverall metrics:\n", mf_gender_test.overall)

# --- Fairness by AgeGroup (Test) ---
mf_age_test = MetricFrame(
    metrics=metrics,
    y_true=y_test,
    y_pred=y_pred_test,
    sensitive_features=dat_test["AgeGroup"]
)
print("\nFairness metrics by AgeGroup (Test):")
print(mf_age_test.by_group)
print("\nOverall metrics:\n", mf_age_test.overall)

print("Unique predictions:", np.unique(y_pred_test, return_counts=True))

import matplotlib.pyplot as plt
import numpy as np

# --- Compute fairness gaps (max - min) from MetricFrames ---
def compute_gaps(mf):
    gaps = {}
    for metric in mf.by_group.columns:   # use columns instead of mf.metrics
        vals = mf.by_group[metric].values
        gaps[metric] = float(np.max(vals) - np.min(vals))
    return gaps

# Gaps for Gender and AgeGroup
gender_gaps = compute_gaps(mf_gender_test)
age_gaps = compute_gaps(mf_age_test)

# --- Prepare data for plotting ---
metrics = list(gender_gaps.keys())  # same metrics for both
gender_vals = [gender_gaps[m] for m in metrics]
age_vals = [age_gaps[m] for m in metrics]

x = np.arange(len(metrics))

# --- Plot ---
plt.figure(figsize=(8,6))
plt.bar(x - 0.2, gender_vals, width=0.4, label="Gender")
plt.bar(x + 0.2, age_vals, width=0.4, label="AgeGroup")

plt.xticks(x, metrics, rotation=20)
plt.ylabel("Fairness Gap (Max-Min Difference)")
plt.title("Fairness Gaps on Test Set")
plt.legend()
plt.tight_layout()
plt.show()

from sklearn.metrics import confusion_matrix

def group_confusion(y_true, y_pred, sensitive_features):
    for g in np.unique(sensitive_features):
        yt = y_true[sensitive_features == g]
        yp = y_pred[sensitive_features == g]
        tn, fp, fn, tp = confusion_matrix(yt, yp).ravel()
        fpr = fp / (fp + tn) if (fp + tn) > 0 else 0
        tpr = tp / (tp + fn) if (tp + fn) > 0 else 0
        print(f"Group {g}: FPR={fpr:.3f}, TPR={tpr:.3f}, size={len(yt)}")

print("Gender groups (Test):")
group_confusion(y_test.values, y_pred_test, dat_test["Gender"].values)

print("\nAgeGroup groups (Test):")
group_confusion(y_test.values, y_pred_test, dat_test["AgeGroup"].values)